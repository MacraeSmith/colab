{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MacraeSmith/helloAI/blob/main/Assignment5theano2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zufu4wflP581",
        "outputId": "af13dbfc-04c8-4a0c-dc87-59511357f49f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"floatx\": \"float32\",\n",
            "    \"epsilon\": 1e-07,\n",
            "    \"backend\": \"tensorflow\",\n",
            "    \"image_data_format\": \"channels_last\"\n",
            "}cat: nn3/keras.json: No such file or directory\n",
            "Cloning into 'nn3'...\n",
            "remote: Enumerating objects: 188, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 188 (delta 42), reused 29 (delta 12), pack-reused 109\u001b[K\n",
            "Receiving objects: 100% (188/188), 94.38 MiB | 20.46 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "Updating files: 100% (108/108), done.\n"
          ]
        }
      ],
      "source": [
        "!cat ~/.keras/keras.json\n",
        "!cat nn3/keras.json > ~/.keras/keras.json\n",
        "!git clone \"https://github.com/kartoone/nn3\"\n",
        "#!git pull\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtVkgt9lO_TO",
        "outputId": "4e9df51d-2b83-441f-d26a-2868f7adc7f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from theano==0.8) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.11 in /usr/local/lib/python3.8/dist-packages (from theano==0.8) (1.7.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from theano==0.8) (1.15.0)\n",
            "Building wheels for collected packages: theano\n",
            "  Building wheel for theano (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for theano: filename=Theano-0.8.0-py3-none-any.whl size=2722137 sha256=596f70d9130f914b420fc49c10a6f2778430abce6dad5f43d31fec5e40e3e382\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/fa/00/251dbd5e561228175439939ac67c8c17484f615a245c2479d8\n",
            "Successfully built theano\n",
            "Installing collected packages: theano\n",
            "Successfully installed theano-0.8.0\n",
            "/content/nn3/src\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!cat nn3/keras.json > ~/.keras/keras.json\n",
        "!pip uninstall -y keras\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow==2.2\n",
        "!pip install keras==2.2.4\n",
        "!pip install pydot-ng\n",
        "!pip install theano==0.8\n",
        "%cd nn3/src\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgOjEgKjVp0o",
        "outputId": "44e2b026-43b1-4c15-b336-4ef34e07c1e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'nn3/src'\n",
            "/content/nn3/src\n",
            "Trying to run under a GPU.  If this is not desired, then modify network3.py\n",
            "to set the GPU flag to False.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING (theano.tensor.blas): We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
            "WARNING:theano.tensor.blas:We did not found a dynamic library into the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training mini-batch number 0\n",
            "Training mini-batch number 1000\n",
            "Training mini-batch number 2000\n",
            "Training mini-batch number 3000\n",
            "Training mini-batch number 4000\n",
            "Epoch 0: validation accuracy 0.9256000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9204000000000001\n",
            "Training mini-batch number 5000\n",
            "Training mini-batch number 6000\n",
            "Training mini-batch number 7000\n",
            "Training mini-batch number 8000\n",
            "Training mini-batch number 9000\n",
            "Epoch 1: validation accuracy 0.9438000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9402\n",
            "Training mini-batch number 10000\n",
            "Training mini-batch number 11000\n",
            "Training mini-batch number 12000\n",
            "Training mini-batch number 13000\n",
            "Training mini-batch number 14000\n",
            "Epoch 2: validation accuracy 0.9538000000000002\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9506000000000001\n",
            "Training mini-batch number 15000\n",
            "Training mini-batch number 16000\n",
            "Training mini-batch number 17000\n",
            "Training mini-batch number 18000\n",
            "Training mini-batch number 19000\n",
            "Epoch 3: validation accuracy 0.9603\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9571000000000002\n",
            "Training mini-batch number 20000\n",
            "Training mini-batch number 21000\n",
            "Training mini-batch number 22000\n",
            "Training mini-batch number 23000\n",
            "Training mini-batch number 24000\n",
            "Epoch 4: validation accuracy 0.9636\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9615\n",
            "Training mini-batch number 25000\n",
            "Training mini-batch number 26000\n",
            "Training mini-batch number 27000\n",
            "Training mini-batch number 28000\n",
            "Training mini-batch number 29000\n",
            "Epoch 5: validation accuracy 0.9673\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9650000000000001\n",
            "Training mini-batch number 30000\n",
            "Training mini-batch number 31000\n",
            "Training mini-batch number 32000\n",
            "Training mini-batch number 33000\n",
            "Training mini-batch number 34000\n",
            "Epoch 6: validation accuracy 0.9698000000000002\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9676000000000001\n",
            "Training mini-batch number 35000\n",
            "Training mini-batch number 36000\n",
            "Training mini-batch number 37000\n",
            "Training mini-batch number 38000\n",
            "Training mini-batch number 39000\n",
            "Epoch 7: validation accuracy 0.9710000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9693\n",
            "Training mini-batch number 40000\n",
            "Training mini-batch number 41000\n",
            "Training mini-batch number 42000\n",
            "Training mini-batch number 43000\n",
            "Training mini-batch number 44000\n",
            "Epoch 8: validation accuracy 0.9715\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9713\n",
            "Training mini-batch number 45000\n",
            "Training mini-batch number 46000\n",
            "Training mini-batch number 47000\n",
            "Training mini-batch number 48000\n",
            "Training mini-batch number 49000\n",
            "Epoch 9: validation accuracy 0.9714\n",
            "Training mini-batch number 50000\n",
            "Training mini-batch number 51000\n",
            "Training mini-batch number 52000\n",
            "Training mini-batch number 53000\n",
            "Training mini-batch number 54000\n",
            "Epoch 10: validation accuracy 0.9721000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9727\n",
            "Training mini-batch number 55000\n",
            "Training mini-batch number 56000\n",
            "Training mini-batch number 57000\n",
            "Training mini-batch number 58000\n",
            "Training mini-batch number 59000\n",
            "Epoch 11: validation accuracy 0.9727\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9734\n",
            "Training mini-batch number 60000\n",
            "Training mini-batch number 61000\n",
            "Training mini-batch number 62000\n",
            "Training mini-batch number 63000\n",
            "Training mini-batch number 64000\n",
            "Epoch 12: validation accuracy 0.9734\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9735\n",
            "Training mini-batch number 65000\n",
            "Training mini-batch number 66000\n",
            "Training mini-batch number 67000\n",
            "Training mini-batch number 68000\n",
            "Training mini-batch number 69000\n",
            "Epoch 13: validation accuracy 0.9739000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9746\n",
            "Training mini-batch number 70000\n",
            "Training mini-batch number 71000\n",
            "Training mini-batch number 72000\n",
            "Training mini-batch number 73000\n",
            "Training mini-batch number 74000\n",
            "Epoch 14: validation accuracy 0.9743\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9748\n",
            "Training mini-batch number 75000\n",
            "Training mini-batch number 76000\n",
            "Training mini-batch number 77000\n",
            "Training mini-batch number 78000\n",
            "Training mini-batch number 79000\n",
            "Epoch 15: validation accuracy 0.9744\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9747\n",
            "Training mini-batch number 80000\n",
            "Training mini-batch number 81000\n",
            "Training mini-batch number 82000\n",
            "Training mini-batch number 83000\n",
            "Training mini-batch number 84000\n",
            "Epoch 16: validation accuracy 0.9747\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9753000000000001\n",
            "Training mini-batch number 85000\n",
            "Training mini-batch number 86000\n",
            "Training mini-batch number 87000\n",
            "Training mini-batch number 88000\n",
            "Training mini-batch number 89000\n",
            "Epoch 17: validation accuracy 0.9746\n",
            "Training mini-batch number 90000\n",
            "Training mini-batch number 91000\n",
            "Training mini-batch number 92000\n",
            "Training mini-batch number 93000\n",
            "Training mini-batch number 94000\n",
            "Epoch 18: validation accuracy 0.9745\n",
            "Training mini-batch number 95000\n",
            "Training mini-batch number 96000\n",
            "Training mini-batch number 97000\n",
            "Training mini-batch number 98000\n",
            "Training mini-batch number 99000\n",
            "Epoch 19: validation accuracy 0.9744\n",
            "Training mini-batch number 100000\n",
            "Training mini-batch number 101000\n",
            "Training mini-batch number 102000\n",
            "Training mini-batch number 103000\n",
            "Training mini-batch number 104000\n",
            "Epoch 20: validation accuracy 0.9748000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9759000000000001\n",
            "Training mini-batch number 105000\n",
            "Training mini-batch number 106000\n",
            "Training mini-batch number 107000\n",
            "Training mini-batch number 108000\n",
            "Training mini-batch number 109000\n",
            "Epoch 21: validation accuracy 0.9752000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9758000000000001\n",
            "Training mini-batch number 110000\n",
            "Training mini-batch number 111000\n",
            "Training mini-batch number 112000\n",
            "Training mini-batch number 113000\n",
            "Training mini-batch number 114000\n",
            "Epoch 22: validation accuracy 0.9749000000000001\n",
            "Training mini-batch number 115000\n",
            "Training mini-batch number 116000\n",
            "Training mini-batch number 117000\n",
            "Training mini-batch number 118000\n",
            "Training mini-batch number 119000\n",
            "Epoch 23: validation accuracy 0.9748\n",
            "Training mini-batch number 120000\n",
            "Training mini-batch number 121000\n",
            "Training mini-batch number 122000\n",
            "Training mini-batch number 123000\n",
            "Training mini-batch number 124000\n",
            "Epoch 24: validation accuracy 0.9746\n",
            "Training mini-batch number 125000\n",
            "Training mini-batch number 126000\n",
            "Training mini-batch number 127000\n",
            "Training mini-batch number 128000\n",
            "Training mini-batch number 129000\n",
            "Epoch 25: validation accuracy 0.9748000000000001\n",
            "Training mini-batch number 130000\n",
            "Training mini-batch number 131000\n",
            "Training mini-batch number 132000\n",
            "Training mini-batch number 133000\n",
            "Training mini-batch number 134000\n",
            "Epoch 26: validation accuracy 0.9748\n",
            "Training mini-batch number 135000\n",
            "Training mini-batch number 136000\n",
            "Training mini-batch number 137000\n",
            "Training mini-batch number 138000\n",
            "Training mini-batch number 139000\n",
            "Epoch 27: validation accuracy 0.9747\n",
            "Training mini-batch number 140000\n",
            "Training mini-batch number 141000\n",
            "Training mini-batch number 142000\n",
            "Training mini-batch number 143000\n",
            "Training mini-batch number 144000\n",
            "Epoch 28: validation accuracy 0.9749000000000001\n",
            "Training mini-batch number 145000\n",
            "Training mini-batch number 146000\n",
            "Training mini-batch number 147000\n",
            "Training mini-batch number 148000\n",
            "Training mini-batch number 149000\n",
            "Epoch 29: validation accuracy 0.975\n",
            "Training mini-batch number 150000\n",
            "Training mini-batch number 151000\n",
            "Training mini-batch number 152000\n",
            "Training mini-batch number 153000\n",
            "Training mini-batch number 154000\n",
            "Epoch 30: validation accuracy 0.9754\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9766000000000001\n",
            "Training mini-batch number 155000\n",
            "Training mini-batch number 156000\n",
            "Training mini-batch number 157000\n",
            "Training mini-batch number 158000\n",
            "Training mini-batch number 159000\n",
            "Epoch 31: validation accuracy 0.9754\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9767\n",
            "Training mini-batch number 160000\n",
            "Training mini-batch number 161000\n",
            "Training mini-batch number 162000\n",
            "Training mini-batch number 163000\n",
            "Training mini-batch number 164000\n",
            "Epoch 32: validation accuracy 0.9753\n",
            "Training mini-batch number 165000\n",
            "Training mini-batch number 166000\n",
            "Training mini-batch number 167000\n",
            "Training mini-batch number 168000\n",
            "Training mini-batch number 169000\n",
            "Epoch 33: validation accuracy 0.9754\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9769000000000001\n",
            "Training mini-batch number 170000\n",
            "Training mini-batch number 171000\n",
            "Training mini-batch number 172000\n",
            "Training mini-batch number 173000\n",
            "Training mini-batch number 174000\n",
            "Epoch 34: validation accuracy 0.9754\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9771000000000002\n",
            "Training mini-batch number 175000\n",
            "Training mini-batch number 176000\n",
            "Training mini-batch number 177000\n",
            "Training mini-batch number 178000\n",
            "Training mini-batch number 179000\n",
            "Epoch 35: validation accuracy 0.9755\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9771000000000002\n",
            "Training mini-batch number 180000\n",
            "Training mini-batch number 181000\n",
            "Training mini-batch number 182000\n",
            "Training mini-batch number 183000\n",
            "Training mini-batch number 184000\n",
            "Epoch 36: validation accuracy 0.9757\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.977\n",
            "Training mini-batch number 185000\n",
            "Training mini-batch number 186000\n",
            "Training mini-batch number 187000\n",
            "Training mini-batch number 188000\n",
            "Training mini-batch number 189000\n",
            "Epoch 37: validation accuracy 0.9757\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9769000000000001\n",
            "Training mini-batch number 190000\n",
            "Training mini-batch number 191000\n",
            "Training mini-batch number 192000\n",
            "Training mini-batch number 193000\n",
            "Training mini-batch number 194000\n",
            "Epoch 38: validation accuracy 0.9757\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9771000000000002\n",
            "Training mini-batch number 195000\n",
            "Training mini-batch number 196000\n",
            "Training mini-batch number 197000\n",
            "Training mini-batch number 198000\n",
            "Training mini-batch number 199000\n",
            "Epoch 39: validation accuracy 0.9757\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9772000000000001\n",
            "Training mini-batch number 200000\n",
            "Training mini-batch number 201000\n",
            "Training mini-batch number 202000\n",
            "Training mini-batch number 203000\n",
            "Training mini-batch number 204000\n",
            "Epoch 40: validation accuracy 0.9758000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9771000000000002\n",
            "Training mini-batch number 205000\n",
            "Training mini-batch number 206000\n",
            "Training mini-batch number 207000\n",
            "Training mini-batch number 208000\n",
            "Training mini-batch number 209000\n",
            "Epoch 41: validation accuracy 0.9759000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.977\n",
            "Training mini-batch number 210000\n",
            "Training mini-batch number 211000\n",
            "Training mini-batch number 212000\n",
            "Training mini-batch number 213000\n",
            "Training mini-batch number 214000\n",
            "Epoch 42: validation accuracy 0.9760000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9772000000000001\n",
            "Training mini-batch number 215000\n",
            "Training mini-batch number 216000\n",
            "Training mini-batch number 217000\n",
            "Training mini-batch number 218000\n",
            "Training mini-batch number 219000\n",
            "Epoch 43: validation accuracy 0.9764\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9772000000000001\n",
            "Training mini-batch number 220000\n",
            "Training mini-batch number 221000\n",
            "Training mini-batch number 222000\n",
            "Training mini-batch number 223000\n",
            "Training mini-batch number 224000\n",
            "Epoch 44: validation accuracy 0.9764\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9773000000000001\n",
            "Training mini-batch number 225000\n",
            "Training mini-batch number 226000\n",
            "Training mini-batch number 227000\n",
            "Training mini-batch number 228000\n",
            "Training mini-batch number 229000\n",
            "Epoch 45: validation accuracy 0.9765\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9773000000000001\n",
            "Training mini-batch number 230000\n",
            "Training mini-batch number 231000\n",
            "Training mini-batch number 232000\n",
            "Training mini-batch number 233000\n",
            "Training mini-batch number 234000\n",
            "Epoch 46: validation accuracy 0.9766\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9773000000000001\n",
            "Training mini-batch number 235000\n",
            "Training mini-batch number 236000\n",
            "Training mini-batch number 237000\n",
            "Training mini-batch number 238000\n",
            "Training mini-batch number 239000\n",
            "Epoch 47: validation accuracy 0.9767\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9774\n",
            "Training mini-batch number 240000\n",
            "Training mini-batch number 241000\n",
            "Training mini-batch number 242000\n",
            "Training mini-batch number 243000\n",
            "Training mini-batch number 244000\n",
            "Epoch 48: validation accuracy 0.9767\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9772000000000001\n",
            "Training mini-batch number 245000\n",
            "Training mini-batch number 246000\n",
            "Training mini-batch number 247000\n",
            "Training mini-batch number 248000\n",
            "Training mini-batch number 249000\n",
            "Epoch 49: validation accuracy 0.9768\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9772000000000001\n",
            "Training mini-batch number 250000\n",
            "Training mini-batch number 251000\n",
            "Training mini-batch number 252000\n",
            "Training mini-batch number 253000\n",
            "Training mini-batch number 254000\n",
            "Epoch 50: validation accuracy 0.9768\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9773000000000001\n",
            "Training mini-batch number 255000\n",
            "Training mini-batch number 256000\n",
            "Training mini-batch number 257000\n",
            "Training mini-batch number 258000\n",
            "Training mini-batch number 259000\n",
            "Epoch 51: validation accuracy 0.9767\n",
            "Training mini-batch number 260000\n",
            "Training mini-batch number 261000\n",
            "Training mini-batch number 262000\n",
            "Training mini-batch number 263000\n",
            "Training mini-batch number 264000\n",
            "Epoch 52: validation accuracy 0.9766\n",
            "Training mini-batch number 265000\n",
            "Training mini-batch number 266000\n",
            "Training mini-batch number 267000\n",
            "Training mini-batch number 268000\n",
            "Training mini-batch number 269000\n",
            "Epoch 53: validation accuracy 0.9766\n",
            "Training mini-batch number 270000\n",
            "Training mini-batch number 271000\n",
            "Training mini-batch number 272000\n",
            "Training mini-batch number 273000\n",
            "Training mini-batch number 274000\n",
            "Epoch 54: validation accuracy 0.9767\n",
            "Training mini-batch number 275000\n",
            "Training mini-batch number 276000\n",
            "Training mini-batch number 277000\n",
            "Training mini-batch number 278000\n",
            "Training mini-batch number 279000\n",
            "Epoch 55: validation accuracy 0.9768000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9771000000000002\n",
            "Training mini-batch number 280000\n",
            "Training mini-batch number 281000\n",
            "Training mini-batch number 282000\n",
            "Training mini-batch number 283000\n",
            "Training mini-batch number 284000\n",
            "Epoch 56: validation accuracy 0.9767\n",
            "Training mini-batch number 285000\n",
            "Training mini-batch number 286000\n",
            "Training mini-batch number 287000\n",
            "Training mini-batch number 288000\n",
            "Training mini-batch number 289000\n",
            "Epoch 57: validation accuracy 0.9767\n",
            "Training mini-batch number 290000\n",
            "Training mini-batch number 291000\n",
            "Training mini-batch number 292000\n",
            "Training mini-batch number 293000\n",
            "Training mini-batch number 294000\n",
            "Epoch 58: validation accuracy 0.9768000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9771000000000002\n",
            "Training mini-batch number 295000\n",
            "Training mini-batch number 296000\n",
            "Training mini-batch number 297000\n",
            "Training mini-batch number 298000\n",
            "Training mini-batch number 299000\n",
            "Epoch 59: validation accuracy 0.9768000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9772000000000001\n",
            "Finished training network.\n",
            "Best validation accuracy of 97.68% obtained at iteration 299999\n",
            "Corresponding test accuracy of 97.72%\n"
          ]
        }
      ],
      "source": [
        "%cd nn3/src\n",
        "\n",
        "import network3\n",
        "from network3 import Network\n",
        "from network3 import ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer\n",
        "training_data, validation_data, test_data = network3.load_data_shared()\n",
        "mini_batch_size = 10\n",
        "net = Network([\n",
        "        FullyConnectedLayer(n_in=784, n_out=100),\n",
        "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
        "net.SGD(training_data, 60, mini_batch_size, 0.1, \n",
        "            validation_data, test_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OSjnQIc8Tanr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# assumes batch size of 10\n",
        "def findTroublesomeImage(net, test_data, batchsize=10):\n",
        "  batches = int(len(test_data[1].eval())/batchsize)\n",
        "  print(batches)\n",
        "  worsta = 1.0\n",
        "  worsti = 0\n",
        "  for i in range(batches):\n",
        "    outputs = net.test_mb_outputs(i)\n",
        "    for a in outputs:\n",
        "      if np.max(a)<worsta:\n",
        "        worsta = np.max(a)\n",
        "        worsti = i\n",
        "  return (worsti, worsta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5gWTjX21Hc_r",
        "outputId": "eb45b198-db0c-4e4c-adde-99fb5ae7c9b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000\n",
            "792\n",
            "0.33106068\n",
            "2\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 19, 39, 28, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 190, 207, 146, 97, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 198, 252, 161, 247, 117, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 102, 253, 253, 253, 244, 193, 35, 5, 39, 28, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 46, 224, 253, 253, 253, 253, 215, 152, 253, 218, 138, 72, 0, 0, 0, 0, 0, 60, 111, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 40, 168, 251, 253, 253, 253, 253, 253, 253, 253, 129, 67, 240, 200, 227, 240, 245, 147, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 67, 185, 222, 233, 253, 253, 253, 253, 144, 50, 174, 69, 221, 253, 253, 46, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 42, 123, 190, 213, 123, 123, 158, 179, 253, 253, 254, 253, 46, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 16, 0, 0, 70, 253, 253, 253, 253, 154, 4, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 24, 87, 252, 230, 250, 234, 44, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 38, 214, 253, 253, 246, 125, 234, 92, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 121, 253, 253, 253, 104, 131, 253, 92, 0, 58, 70, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 89, 246, 253, 253, 253, 104, 130, 228, 195, 82, 239, 244, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 72, 131, 253, 253, 253, 253, 253, 190, 233, 254, 253, 229, 55, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 143, 236, 253, 253, 253, 253, 212, 122, 131, 38, 38, 125, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 31, 250, 251, 246, 170, 92, 31, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 76, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[2.10151110e-14, 9.99900281e-01, 2.65018874e-09, 2.45518379e-07,\n",
              "        2.60682960e-08, 2.74178183e-06, 2.34013342e-07, 1.23693397e-07,\n",
              "        9.63487400e-05, 1.39669325e-08],\n",
              "       [1.87226316e-14, 9.99828100e-01, 2.78612031e-08, 2.97162643e-07,\n",
              "        6.27731083e-07, 8.63345129e-09, 3.13173217e-07, 4.45060941e-05,\n",
              "        1.26140105e-04, 5.92527538e-09],\n",
              "       [1.71432042e-13, 2.99585010e-11, 6.47779085e-13, 7.46084999e-11,\n",
              "        9.99998927e-01, 2.94612363e-07, 1.28444200e-09, 6.60396404e-10,\n",
              "        2.91895674e-07, 4.71046519e-07],\n",
              "       [3.72850328e-09, 7.32095350e-06, 9.99075353e-01, 3.83260522e-06,\n",
              "        9.11113515e-04, 1.81367259e-08, 2.13609951e-06, 1.49706046e-11,\n",
              "        6.88079069e-08, 1.55685271e-07],\n",
              "       [4.33799386e-14, 5.84480450e-11, 2.88147956e-12, 2.15936296e-07,\n",
              "        2.59982753e-05, 6.71937419e-12, 1.45552295e-14, 5.16360821e-09,\n",
              "        2.71885270e-08, 9.99973774e-01],\n",
              "       [3.24811671e-11, 2.31963284e-08, 1.34201471e-07, 4.17675710e-06,\n",
              "        3.68955127e-12, 1.32881050e-11, 1.68707748e-16, 9.99995649e-01,\n",
              "        1.18681454e-09, 2.30015935e-08],\n",
              "       [3.82756667e-07, 9.15935743e-06, 8.11560079e-04, 1.73817476e-04,\n",
              "        1.01292215e-03, 9.82524853e-07, 9.18081522e-01, 7.63576925e-02,\n",
              "        3.54520837e-03, 6.74239254e-06],\n",
              "       [9.74055092e-06, 2.81394374e-08, 2.76125320e-07, 1.45527801e-09,\n",
              "        1.45593693e-03, 9.93531585e-01, 4.97267256e-03, 1.44565870e-09,\n",
              "        2.71274148e-05, 2.65078938e-06],\n",
              "       [1.24385824e-05, 9.97573853e-01, 5.62994719e-05, 1.40025168e-05,\n",
              "        2.27879937e-05, 2.38448469e-04, 1.66769512e-03, 3.01893147e-06,\n",
              "        4.11446206e-04, 2.37198279e-08],\n",
              "       [1.36274604e-13, 9.99972463e-01, 9.06350439e-10, 1.62389625e-07,\n",
              "        6.00375998e-08, 1.05927043e-07, 1.60595718e-07, 9.94586844e-06,\n",
              "        1.66602949e-05, 4.33820645e-07]], dtype=float32)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(worsti, worsta) = findTroublesomeImage(net, test_data)\n",
        "print(worsti)\n",
        "print(worsta)\n",
        "\n",
        "print(test_data[1][4176].eval())\n",
        "pixeldata = test_data[0][4176].reshape((28,28)).eval()\n",
        "pixeldata = [[round(p*255) for p in pix] for pix in pixeldata]\n",
        "print(pixeldata)\n",
        "plt.figure()\n",
        "plt.imshow(pixeldata, cmap=\"gray_r\")\n",
        "net.test_mb_outputs(417)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tzPpIsXuF6Eb",
        "outputId": "45bd6c5a-0aa8-49e6-8bd7-6447b3a2e2db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: Theano\n",
            "Version: 0.8.0\n",
            "Summary: Optimizing compiler for evaluating mathematical expressions on CPUs and GPUs.\n",
            "Home-page: http://deeplearning.net/software/theano/\n",
            "Author: LISA laboratory, University of Montreal\n",
            "Author-email: theano-dev@googlegroups.com\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.8/dist-packages\n",
            "Requires: numpy, scipy, six\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show theano"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Tm4UvR1QPBO2",
        "outputId": "312c3a3b-babd-484b-f083-6afa2e183a1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expanding the MNIST training set\n",
            "Expanding image number 1000\n",
            "Expanding image number 2000\n",
            "Expanding image number 3000\n",
            "Expanding image number 4000\n",
            "Expanding image number 5000\n",
            "Expanding image number 6000\n",
            "Expanding image number 7000\n",
            "Expanding image number 8000\n",
            "Expanding image number 9000\n",
            "Expanding image number 10000\n",
            "Expanding image number 11000\n",
            "Expanding image number 12000\n",
            "Expanding image number 13000\n",
            "Expanding image number 14000\n",
            "Expanding image number 15000\n",
            "Expanding image number 16000\n",
            "Expanding image number 17000\n",
            "Expanding image number 18000\n",
            "Expanding image number 19000\n",
            "Expanding image number 20000\n",
            "Expanding image number 21000\n",
            "Expanding image number 22000\n",
            "Expanding image number 23000\n",
            "Expanding image number 24000\n",
            "Expanding image number 25000\n",
            "Expanding image number 26000\n",
            "Expanding image number 27000\n",
            "Expanding image number 28000\n",
            "Expanding image number 29000\n",
            "Expanding image number 30000\n",
            "Expanding image number 31000\n",
            "Expanding image number 32000\n",
            "Expanding image number 33000\n",
            "Expanding image number 34000\n",
            "Expanding image number 35000\n",
            "Expanding image number 36000\n",
            "Expanding image number 37000\n",
            "Expanding image number 38000\n",
            "Expanding image number 39000\n",
            "Expanding image number 40000\n",
            "Expanding image number 41000\n",
            "Expanding image number 42000\n",
            "Expanding image number 43000\n",
            "Expanding image number 44000\n",
            "Expanding image number 45000\n",
            "Expanding image number 46000\n",
            "Expanding image number 47000\n",
            "Expanding image number 48000\n",
            "Expanding image number 49000\n",
            "Expanding image number 50000\n",
            "Saving expanded data. This may take a few minutes.\n"
          ]
        }
      ],
      "source": [
        "!python expand_mnist.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTnfKdTXKVjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9bd3ec-800d-4da2-bfb9-fa8507cd2ffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training mini-batch number 0\n",
            "Training mini-batch number 1000\n",
            "Training mini-batch number 2000\n",
            "Training mini-batch number 3000\n",
            "Training mini-batch number 4000\n",
            "Training mini-batch number 5000\n",
            "Training mini-batch number 6000\n",
            "Training mini-batch number 7000\n",
            "Training mini-batch number 8000\n",
            "Training mini-batch number 9000\n",
            "Training mini-batch number 10000\n",
            "Training mini-batch number 11000\n",
            "Training mini-batch number 12000\n",
            "Training mini-batch number 13000\n",
            "Training mini-batch number 14000\n",
            "Training mini-batch number 15000\n",
            "Training mini-batch number 16000\n",
            "Training mini-batch number 17000\n",
            "Training mini-batch number 18000\n",
            "Training mini-batch number 19000\n",
            "Training mini-batch number 20000\n",
            "Training mini-batch number 21000\n",
            "Training mini-batch number 22000\n",
            "Training mini-batch number 23000\n",
            "Training mini-batch number 24000\n",
            "Epoch 0: validation accuracy 0.9876000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9904000000000001\n",
            "Training mini-batch number 25000\n",
            "Training mini-batch number 26000\n",
            "Training mini-batch number 27000\n",
            "Training mini-batch number 28000\n",
            "Training mini-batch number 29000\n",
            "Training mini-batch number 30000\n",
            "Training mini-batch number 31000\n",
            "Training mini-batch number 32000\n",
            "Training mini-batch number 33000\n",
            "Training mini-batch number 34000\n",
            "Training mini-batch number 35000\n",
            "Training mini-batch number 36000\n",
            "Training mini-batch number 37000\n",
            "Training mini-batch number 38000\n",
            "Training mini-batch number 39000\n",
            "Training mini-batch number 40000\n",
            "Training mini-batch number 41000\n",
            "Training mini-batch number 42000\n",
            "Training mini-batch number 43000\n",
            "Training mini-batch number 44000\n",
            "Training mini-batch number 45000\n",
            "Training mini-batch number 46000\n",
            "Training mini-batch number 47000\n",
            "Training mini-batch number 48000\n",
            "Training mini-batch number 49000\n",
            "Epoch 1: validation accuracy 0.9912000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9919000000000001\n",
            "Training mini-batch number 50000\n",
            "Training mini-batch number 51000\n",
            "Training mini-batch number 52000\n",
            "Training mini-batch number 53000\n",
            "Training mini-batch number 54000\n",
            "Training mini-batch number 55000\n",
            "Training mini-batch number 56000\n",
            "Training mini-batch number 57000\n",
            "Training mini-batch number 58000\n",
            "Training mini-batch number 59000\n",
            "Training mini-batch number 60000\n",
            "Training mini-batch number 61000\n",
            "Training mini-batch number 62000\n",
            "Training mini-batch number 63000\n",
            "Training mini-batch number 64000\n",
            "Training mini-batch number 65000\n",
            "Training mini-batch number 66000\n",
            "Training mini-batch number 67000\n",
            "Training mini-batch number 68000\n",
            "Training mini-batch number 69000\n",
            "Training mini-batch number 70000\n",
            "Training mini-batch number 71000\n",
            "Training mini-batch number 72000\n",
            "Training mini-batch number 73000\n",
            "Training mini-batch number 74000\n",
            "Epoch 2: validation accuracy 0.9912000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9914000000000001\n",
            "Training mini-batch number 75000\n",
            "Training mini-batch number 76000\n",
            "Training mini-batch number 77000\n",
            "Training mini-batch number 78000\n",
            "Training mini-batch number 79000\n",
            "Training mini-batch number 80000\n",
            "Training mini-batch number 81000\n",
            "Training mini-batch number 82000\n",
            "Training mini-batch number 83000\n",
            "Training mini-batch number 84000\n",
            "Training mini-batch number 85000\n",
            "Training mini-batch number 86000\n",
            "Training mini-batch number 87000\n",
            "Training mini-batch number 88000\n",
            "Training mini-batch number 89000\n",
            "Training mini-batch number 90000\n",
            "Training mini-batch number 91000\n",
            "Training mini-batch number 92000\n",
            "Training mini-batch number 93000\n",
            "Training mini-batch number 94000\n",
            "Training mini-batch number 95000\n",
            "Training mini-batch number 96000\n",
            "Training mini-batch number 97000\n",
            "Training mini-batch number 98000\n",
            "Training mini-batch number 99000\n",
            "Epoch 3: validation accuracy 0.9915\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9910000000000001\n",
            "Training mini-batch number 100000\n",
            "Training mini-batch number 101000\n",
            "Training mini-batch number 102000\n",
            "Training mini-batch number 103000\n",
            "Training mini-batch number 104000\n",
            "Training mini-batch number 105000\n",
            "Training mini-batch number 106000\n",
            "Training mini-batch number 107000\n",
            "Training mini-batch number 108000\n",
            "Training mini-batch number 109000\n",
            "Training mini-batch number 110000\n",
            "Training mini-batch number 111000\n",
            "Training mini-batch number 112000\n",
            "Training mini-batch number 113000\n",
            "Training mini-batch number 114000\n",
            "Training mini-batch number 115000\n",
            "Training mini-batch number 116000\n",
            "Training mini-batch number 117000\n",
            "Training mini-batch number 118000\n",
            "Training mini-batch number 119000\n",
            "Training mini-batch number 120000\n",
            "Training mini-batch number 121000\n",
            "Training mini-batch number 122000\n",
            "Training mini-batch number 123000\n",
            "Training mini-batch number 124000\n",
            "Epoch 4: validation accuracy 0.9924000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9917999999999999\n",
            "Training mini-batch number 125000\n",
            "Training mini-batch number 126000\n",
            "Training mini-batch number 127000\n",
            "Training mini-batch number 128000\n",
            "Training mini-batch number 129000\n",
            "Training mini-batch number 130000\n",
            "Training mini-batch number 131000\n",
            "Training mini-batch number 132000\n",
            "Training mini-batch number 133000\n",
            "Training mini-batch number 134000\n",
            "Training mini-batch number 135000\n",
            "Training mini-batch number 136000\n",
            "Training mini-batch number 137000\n",
            "Training mini-batch number 138000\n",
            "Training mini-batch number 139000\n",
            "Training mini-batch number 140000\n",
            "Training mini-batch number 141000\n",
            "Training mini-batch number 142000\n",
            "Training mini-batch number 143000\n",
            "Training mini-batch number 144000\n",
            "Training mini-batch number 145000\n",
            "Training mini-batch number 146000\n",
            "Training mini-batch number 147000\n",
            "Training mini-batch number 148000\n",
            "Training mini-batch number 149000\n",
            "Epoch 5: validation accuracy 0.9915\n",
            "Training mini-batch number 150000\n",
            "Training mini-batch number 151000\n",
            "Training mini-batch number 152000\n",
            "Training mini-batch number 153000\n",
            "Training mini-batch number 154000\n",
            "Training mini-batch number 155000\n",
            "Training mini-batch number 156000\n",
            "Training mini-batch number 157000\n",
            "Training mini-batch number 158000\n",
            "Training mini-batch number 159000\n",
            "Training mini-batch number 160000\n",
            "Training mini-batch number 161000\n",
            "Training mini-batch number 162000\n",
            "Training mini-batch number 163000\n",
            "Training mini-batch number 164000\n",
            "Training mini-batch number 165000\n",
            "Training mini-batch number 166000\n",
            "Training mini-batch number 167000\n",
            "Training mini-batch number 168000\n",
            "Training mini-batch number 169000\n",
            "Training mini-batch number 170000\n",
            "Training mini-batch number 171000\n",
            "Training mini-batch number 172000\n",
            "Training mini-batch number 173000\n",
            "Training mini-batch number 174000\n",
            "Epoch 6: validation accuracy 0.9913000000000001\n",
            "Training mini-batch number 175000\n",
            "Training mini-batch number 176000\n",
            "Training mini-batch number 177000\n",
            "Training mini-batch number 178000\n",
            "Training mini-batch number 179000\n",
            "Training mini-batch number 180000\n",
            "Training mini-batch number 181000\n",
            "Training mini-batch number 182000\n",
            "Training mini-batch number 183000\n",
            "Training mini-batch number 184000\n",
            "Training mini-batch number 185000\n",
            "Training mini-batch number 186000\n",
            "Training mini-batch number 187000\n",
            "Training mini-batch number 188000\n",
            "Training mini-batch number 189000\n",
            "Training mini-batch number 190000\n",
            "Training mini-batch number 191000\n",
            "Training mini-batch number 192000\n",
            "Training mini-batch number 193000\n",
            "Training mini-batch number 194000\n",
            "Training mini-batch number 195000\n",
            "Training mini-batch number 196000\n",
            "Training mini-batch number 197000\n",
            "Training mini-batch number 198000\n",
            "Training mini-batch number 199000\n",
            "Epoch 7: validation accuracy 0.9921\n",
            "Training mini-batch number 200000\n",
            "Training mini-batch number 201000\n",
            "Training mini-batch number 202000\n",
            "Training mini-batch number 203000\n",
            "Training mini-batch number 204000\n",
            "Training mini-batch number 205000\n",
            "Training mini-batch number 206000\n",
            "Training mini-batch number 207000\n",
            "Training mini-batch number 208000\n",
            "Training mini-batch number 209000\n",
            "Training mini-batch number 210000\n",
            "Training mini-batch number 211000\n",
            "Training mini-batch number 212000\n",
            "Training mini-batch number 213000\n",
            "Training mini-batch number 214000\n",
            "Training mini-batch number 215000\n",
            "Training mini-batch number 216000\n",
            "Training mini-batch number 217000\n",
            "Training mini-batch number 218000\n",
            "Training mini-batch number 219000\n",
            "Training mini-batch number 220000\n",
            "Training mini-batch number 221000\n",
            "Training mini-batch number 222000\n",
            "Training mini-batch number 223000\n",
            "Training mini-batch number 224000\n",
            "Epoch 8: validation accuracy 0.9921\n",
            "Training mini-batch number 225000\n",
            "Training mini-batch number 226000\n",
            "Training mini-batch number 227000\n",
            "Training mini-batch number 228000\n",
            "Training mini-batch number 229000\n",
            "Training mini-batch number 230000\n",
            "Training mini-batch number 231000\n",
            "Training mini-batch number 232000\n",
            "Training mini-batch number 233000\n",
            "Training mini-batch number 234000\n",
            "Training mini-batch number 235000\n",
            "Training mini-batch number 236000\n",
            "Training mini-batch number 237000\n",
            "Training mini-batch number 238000\n",
            "Training mini-batch number 239000\n",
            "Training mini-batch number 240000\n",
            "Training mini-batch number 241000\n",
            "Training mini-batch number 242000\n",
            "Training mini-batch number 243000\n",
            "Training mini-batch number 244000\n",
            "Training mini-batch number 245000\n",
            "Training mini-batch number 246000\n",
            "Training mini-batch number 247000\n",
            "Training mini-batch number 248000\n",
            "Training mini-batch number 249000\n",
            "Epoch 9: validation accuracy 0.9929000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9920999999999999\n",
            "Training mini-batch number 250000\n",
            "Training mini-batch number 251000\n",
            "Training mini-batch number 252000\n",
            "Training mini-batch number 253000\n",
            "Training mini-batch number 254000\n",
            "Training mini-batch number 255000\n",
            "Training mini-batch number 256000\n",
            "Training mini-batch number 257000\n",
            "Training mini-batch number 258000\n",
            "Training mini-batch number 259000\n",
            "Training mini-batch number 260000\n",
            "Training mini-batch number 261000\n",
            "Training mini-batch number 262000\n",
            "Training mini-batch number 263000\n",
            "Training mini-batch number 264000\n",
            "Training mini-batch number 265000\n",
            "Training mini-batch number 266000\n",
            "Training mini-batch number 267000\n",
            "Training mini-batch number 268000\n",
            "Training mini-batch number 269000\n",
            "Training mini-batch number 270000\n",
            "Training mini-batch number 271000\n",
            "Training mini-batch number 272000\n",
            "Training mini-batch number 273000\n",
            "Training mini-batch number 274000\n",
            "Epoch 10: validation accuracy 0.9934000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9931\n",
            "Training mini-batch number 275000\n",
            "Training mini-batch number 276000\n",
            "Training mini-batch number 277000\n",
            "Training mini-batch number 278000\n",
            "Training mini-batch number 279000\n",
            "Training mini-batch number 280000\n",
            "Training mini-batch number 281000\n",
            "Training mini-batch number 282000\n",
            "Training mini-batch number 283000\n",
            "Training mini-batch number 284000\n",
            "Training mini-batch number 285000\n",
            "Training mini-batch number 286000\n",
            "Training mini-batch number 287000\n",
            "Training mini-batch number 288000\n",
            "Training mini-batch number 289000\n",
            "Training mini-batch number 290000\n",
            "Training mini-batch number 291000\n",
            "Training mini-batch number 292000\n",
            "Training mini-batch number 293000\n",
            "Training mini-batch number 294000\n",
            "Training mini-batch number 295000\n",
            "Training mini-batch number 296000\n",
            "Training mini-batch number 297000\n",
            "Training mini-batch number 298000\n",
            "Training mini-batch number 299000\n",
            "Epoch 11: validation accuracy 0.9935\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9927\n",
            "Training mini-batch number 300000\n",
            "Training mini-batch number 301000\n",
            "Training mini-batch number 302000\n",
            "Training mini-batch number 303000\n",
            "Training mini-batch number 304000\n",
            "Training mini-batch number 305000\n",
            "Training mini-batch number 306000\n",
            "Training mini-batch number 307000\n",
            "Training mini-batch number 308000\n",
            "Training mini-batch number 309000\n",
            "Training mini-batch number 310000\n",
            "Training mini-batch number 311000\n",
            "Training mini-batch number 312000\n",
            "Training mini-batch number 313000\n",
            "Training mini-batch number 314000\n",
            "Training mini-batch number 315000\n",
            "Training mini-batch number 316000\n",
            "Training mini-batch number 317000\n",
            "Training mini-batch number 318000\n",
            "Training mini-batch number 319000\n",
            "Training mini-batch number 320000\n",
            "Training mini-batch number 321000\n",
            "Training mini-batch number 322000\n",
            "Training mini-batch number 323000\n",
            "Training mini-batch number 324000\n",
            "Epoch 12: validation accuracy 0.9925999999999999\n",
            "Training mini-batch number 325000\n",
            "Training mini-batch number 326000\n",
            "Training mini-batch number 327000\n",
            "Training mini-batch number 328000\n",
            "Training mini-batch number 329000\n",
            "Training mini-batch number 330000\n",
            "Training mini-batch number 331000\n",
            "Training mini-batch number 332000\n",
            "Training mini-batch number 333000\n",
            "Training mini-batch number 334000\n",
            "Training mini-batch number 335000\n",
            "Training mini-batch number 336000\n",
            "Training mini-batch number 337000\n",
            "Training mini-batch number 338000\n",
            "Training mini-batch number 339000\n",
            "Training mini-batch number 340000\n",
            "Training mini-batch number 341000\n",
            "Training mini-batch number 342000\n",
            "Training mini-batch number 343000\n",
            "Training mini-batch number 344000\n",
            "Training mini-batch number 345000\n",
            "Training mini-batch number 346000\n",
            "Training mini-batch number 347000\n",
            "Training mini-batch number 348000\n",
            "Training mini-batch number 349000\n",
            "Epoch 13: validation accuracy 0.9925\n",
            "Training mini-batch number 350000\n",
            "Training mini-batch number 351000\n",
            "Training mini-batch number 352000\n",
            "Training mini-batch number 353000\n",
            "Training mini-batch number 354000\n",
            "Training mini-batch number 355000\n",
            "Training mini-batch number 356000\n",
            "Training mini-batch number 357000\n",
            "Training mini-batch number 358000\n",
            "Training mini-batch number 359000\n",
            "Training mini-batch number 360000\n",
            "Training mini-batch number 361000\n",
            "Training mini-batch number 362000\n",
            "Training mini-batch number 363000\n",
            "Training mini-batch number 364000\n",
            "Training mini-batch number 365000\n",
            "Training mini-batch number 366000\n",
            "Training mini-batch number 367000\n",
            "Training mini-batch number 368000\n",
            "Training mini-batch number 369000\n",
            "Training mini-batch number 370000\n",
            "Training mini-batch number 371000\n",
            "Training mini-batch number 372000\n",
            "Training mini-batch number 373000\n",
            "Training mini-batch number 374000\n",
            "Epoch 14: validation accuracy 0.9922000000000001\n",
            "Training mini-batch number 375000\n",
            "Training mini-batch number 376000\n",
            "Training mini-batch number 377000\n",
            "Training mini-batch number 378000\n",
            "Training mini-batch number 379000\n",
            "Training mini-batch number 380000\n",
            "Training mini-batch number 381000\n",
            "Training mini-batch number 382000\n",
            "Training mini-batch number 383000\n",
            "Training mini-batch number 384000\n",
            "Training mini-batch number 385000\n",
            "Training mini-batch number 386000\n",
            "Training mini-batch number 387000\n",
            "Training mini-batch number 388000\n",
            "Training mini-batch number 389000\n",
            "Training mini-batch number 390000\n",
            "Training mini-batch number 391000\n",
            "Training mini-batch number 392000\n",
            "Training mini-batch number 393000\n",
            "Training mini-batch number 394000\n",
            "Training mini-batch number 395000\n",
            "Training mini-batch number 396000\n",
            "Training mini-batch number 397000\n",
            "Training mini-batch number 398000\n",
            "Training mini-batch number 399000\n",
            "Epoch 15: validation accuracy 0.991\n",
            "Training mini-batch number 400000\n",
            "Training mini-batch number 401000\n",
            "Training mini-batch number 402000\n",
            "Training mini-batch number 403000\n",
            "Training mini-batch number 404000\n",
            "Training mini-batch number 405000\n",
            "Training mini-batch number 406000\n",
            "Training mini-batch number 407000\n",
            "Training mini-batch number 408000\n",
            "Training mini-batch number 409000\n",
            "Training mini-batch number 410000\n",
            "Training mini-batch number 411000\n",
            "Training mini-batch number 412000\n",
            "Training mini-batch number 413000\n",
            "Training mini-batch number 414000\n",
            "Training mini-batch number 415000\n",
            "Training mini-batch number 416000\n",
            "Training mini-batch number 417000\n",
            "Training mini-batch number 418000\n",
            "Training mini-batch number 419000\n",
            "Training mini-batch number 420000\n",
            "Training mini-batch number 421000\n",
            "Training mini-batch number 422000\n",
            "Training mini-batch number 423000\n",
            "Training mini-batch number 424000\n",
            "Epoch 16: validation accuracy 0.9937\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9933\n",
            "Training mini-batch number 425000\n",
            "Training mini-batch number 426000\n",
            "Training mini-batch number 427000\n",
            "Training mini-batch number 428000\n",
            "Training mini-batch number 429000\n",
            "Training mini-batch number 430000\n",
            "Training mini-batch number 431000\n",
            "Training mini-batch number 432000\n",
            "Training mini-batch number 433000\n",
            "Training mini-batch number 434000\n",
            "Training mini-batch number 435000\n",
            "Training mini-batch number 436000\n",
            "Training mini-batch number 437000\n",
            "Training mini-batch number 438000\n",
            "Training mini-batch number 439000\n",
            "Training mini-batch number 440000\n",
            "Training mini-batch number 441000\n",
            "Training mini-batch number 442000\n",
            "Training mini-batch number 443000\n",
            "Training mini-batch number 444000\n",
            "Training mini-batch number 445000\n",
            "Training mini-batch number 446000\n",
            "Training mini-batch number 447000\n",
            "Training mini-batch number 448000\n",
            "Training mini-batch number 449000\n",
            "Epoch 17: validation accuracy 0.9939000000000001\n",
            "This is the best validation accuracy to date.\n",
            "The corresponding test accuracy is 0.9929000000000001\n",
            "Training mini-batch number 450000\n",
            "Training mini-batch number 451000\n",
            "Training mini-batch number 452000\n",
            "Training mini-batch number 453000\n",
            "Training mini-batch number 454000\n",
            "Training mini-batch number 455000\n",
            "Training mini-batch number 456000\n",
            "Training mini-batch number 457000\n",
            "Training mini-batch number 458000\n",
            "Training mini-batch number 459000\n",
            "Training mini-batch number 460000\n",
            "Training mini-batch number 461000\n",
            "Training mini-batch number 462000\n",
            "Training mini-batch number 463000\n",
            "Training mini-batch number 464000\n",
            "Training mini-batch number 465000\n",
            "Training mini-batch number 466000\n",
            "Training mini-batch number 467000\n",
            "Training mini-batch number 468000\n",
            "Training mini-batch number 469000\n",
            "Training mini-batch number 470000\n",
            "Training mini-batch number 471000\n",
            "Training mini-batch number 472000\n",
            "Training mini-batch number 473000\n",
            "Training mini-batch number 474000\n",
            "Epoch 18: validation accuracy 0.9932000000000001\n",
            "Training mini-batch number 475000\n",
            "Training mini-batch number 476000\n",
            "Training mini-batch number 477000\n",
            "Training mini-batch number 478000\n",
            "Training mini-batch number 479000\n",
            "Training mini-batch number 480000\n",
            "Training mini-batch number 481000\n",
            "Training mini-batch number 482000\n",
            "Training mini-batch number 483000\n",
            "Training mini-batch number 484000\n",
            "Training mini-batch number 485000\n",
            "Training mini-batch number 486000\n",
            "Training mini-batch number 487000\n",
            "Training mini-batch number 488000\n",
            "Training mini-batch number 489000\n",
            "Training mini-batch number 490000\n",
            "Training mini-batch number 491000\n",
            "Training mini-batch number 492000\n",
            "Training mini-batch number 493000\n",
            "Training mini-batch number 494000\n",
            "Training mini-batch number 495000\n",
            "Training mini-batch number 496000\n",
            "Training mini-batch number 497000\n",
            "Training mini-batch number 498000\n",
            "Training mini-batch number 499000\n",
            "Epoch 19: validation accuracy 0.9921000000000001\n",
            "Training mini-batch number 500000\n",
            "Training mini-batch number 501000\n",
            "Training mini-batch number 502000\n",
            "Training mini-batch number 503000\n",
            "Training mini-batch number 504000\n",
            "Training mini-batch number 505000\n",
            "Training mini-batch number 506000\n",
            "Training mini-batch number 507000\n",
            "Training mini-batch number 508000\n",
            "Training mini-batch number 509000\n",
            "Training mini-batch number 510000\n",
            "Training mini-batch number 511000\n",
            "Training mini-batch number 512000\n",
            "Training mini-batch number 513000\n",
            "Training mini-batch number 514000\n",
            "Training mini-batch number 515000\n",
            "Training mini-batch number 516000\n",
            "Training mini-batch number 517000\n",
            "Training mini-batch number 518000\n",
            "Training mini-batch number 519000\n",
            "Training mini-batch number 520000\n",
            "Training mini-batch number 521000\n",
            "Training mini-batch number 522000\n",
            "Training mini-batch number 523000\n",
            "Training mini-batch number 524000\n",
            "Epoch 20: validation accuracy 0.9932000000000001\n",
            "Training mini-batch number 525000\n",
            "Training mini-batch number 526000\n",
            "Training mini-batch number 527000\n",
            "Training mini-batch number 528000\n",
            "Training mini-batch number 529000\n",
            "Training mini-batch number 530000\n",
            "Training mini-batch number 531000\n",
            "Training mini-batch number 532000\n",
            "Training mini-batch number 533000\n",
            "Training mini-batch number 534000\n",
            "Training mini-batch number 535000\n",
            "Training mini-batch number 536000\n",
            "Training mini-batch number 537000\n",
            "Training mini-batch number 538000\n",
            "Training mini-batch number 539000\n",
            "Training mini-batch number 540000\n",
            "Training mini-batch number 541000\n",
            "Training mini-batch number 542000\n",
            "Training mini-batch number 543000\n",
            "Training mini-batch number 544000\n",
            "Training mini-batch number 545000\n",
            "Training mini-batch number 546000\n",
            "Training mini-batch number 547000\n",
            "Training mini-batch number 548000\n",
            "Training mini-batch number 549000\n",
            "Epoch 21: validation accuracy 0.9917999999999999\n",
            "Training mini-batch number 550000\n",
            "Training mini-batch number 551000\n",
            "Training mini-batch number 552000\n",
            "Training mini-batch number 553000\n",
            "Training mini-batch number 554000\n",
            "Training mini-batch number 555000\n",
            "Training mini-batch number 556000\n",
            "Training mini-batch number 557000\n",
            "Training mini-batch number 558000\n",
            "Training mini-batch number 559000\n",
            "Training mini-batch number 560000\n",
            "Training mini-batch number 561000\n",
            "Training mini-batch number 562000\n",
            "Training mini-batch number 563000\n",
            "Training mini-batch number 564000\n",
            "Training mini-batch number 565000\n",
            "Training mini-batch number 566000\n",
            "Training mini-batch number 567000\n",
            "Training mini-batch number 568000\n",
            "Training mini-batch number 569000\n",
            "Training mini-batch number 570000\n",
            "Training mini-batch number 571000\n",
            "Training mini-batch number 572000\n",
            "Training mini-batch number 573000\n",
            "Training mini-batch number 574000\n",
            "Epoch 22: validation accuracy 0.9934000000000001\n",
            "Training mini-batch number 575000\n",
            "Training mini-batch number 576000\n",
            "Training mini-batch number 577000\n",
            "Training mini-batch number 578000\n",
            "Training mini-batch number 579000\n",
            "Training mini-batch number 580000\n",
            "Training mini-batch number 581000\n",
            "Training mini-batch number 582000\n",
            "Training mini-batch number 583000\n",
            "Training mini-batch number 584000\n",
            "Training mini-batch number 585000\n",
            "Training mini-batch number 586000\n",
            "Training mini-batch number 587000\n",
            "Training mini-batch number 588000\n",
            "Training mini-batch number 589000\n",
            "Training mini-batch number 590000\n",
            "Training mini-batch number 591000\n",
            "Training mini-batch number 592000\n",
            "Training mini-batch number 593000\n",
            "Training mini-batch number 594000\n",
            "Training mini-batch number 595000\n",
            "Training mini-batch number 596000\n"
          ]
        }
      ],
      "source": [
        "from network3 import ReLU\n",
        "import time\n",
        "start = time.time()\n",
        "expanded_training_data, _, _ = network3.load_data_shared(\n",
        "        \"../data/mnist_expanded.pkl.gz\")\n",
        "net = Network([\n",
        "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
        "                      filter_shape=(20, 1, 5, 5), \n",
        "                      poolsize=(2, 2), \n",
        "                      activation_fn=ReLU),\n",
        "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
        "                      filter_shape=(40, 20, 5, 5), \n",
        "                      poolsize=(2, 2), \n",
        "                      activation_fn=ReLU),\n",
        "        FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU),\n",
        "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
        "net.SGD(expanded_training_data, 60, mini_batch_size, 0.03, \n",
        "            validation_data, test_data, lmbda=0.1)\n",
        "finish = time.time()\n",
        "elapsed = finish - start\n",
        "print(elapsed)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}